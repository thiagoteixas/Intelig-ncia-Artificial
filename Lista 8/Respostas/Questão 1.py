# -*- coding: utf-8 -*-
"""Kmeans.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JUl4MfT6qZW80B90loLn-EkFW2csmlBZ
"""

!pip install plotly --upgrade
!pip install kneed # To install only knee-detection algorithm

import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import scipy as sp
from kneed import DataGenerator, KneeLocator #para mostrar o n√∫mero de grupos ideal do agrupamento
from sklearn.cluster import KMeans #Importando a fun√ß√£o Kmeans
from sklearn.preprocessing import StandardScaler #Fun√ß√£o utilizada para normaliza√ß√£o dos dados
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import MinMaxScaler #Fun√ß√£o utilizada para normaliza√ß√£o dos dados

import pandas as pd
base= pd.read_csv('Iris.csv', sep=',',encoding='cp1252')
print(base)

"""Identificamos o Z-score ( segundo link abaixo ) para determinar outliers

https://docs.oracle.com/cloud/help/pt_BR/pbcs_common/PFUSU/insights_metrics_Z-Score.htm#PFUSU-GUID-640CEBD1-33A2-4B3C-BD81-EB283F82D879
"""

entries_zscores = base.iloc[:, 0:4].apply(sp.stats.zscore)
print(entries_zscores)

"""Outliers cont√©m z-scores maior que 3 ou menor que -3, ent√£o separamos estas entradas."""

outliers = (entries_zscores.abs() > 3).any(axis=1)
print(base[outliers])

"""Normalizando os dados"""

minmax_scaler = MinMaxScaler()
normalized_base = pd.DataFrame(minmax_scaler.fit_transform(base.iloc[:, :-1]), columns=base.columns[:-1])
normalized_base['class'] = base['class']
print(normalized_base)

"""#Elbow

Encontrar o n√∫mero de clusteres ideal.
O m√©todo Elbow √© utilizado para determinar o n√∫mero ideal de clusters em um conjunto de dados. Ele faz isso ao tra√ßar a soma dos erros quadr√°ticos (sum of squared errors, SSE) ou in√©rcia para diferentes valores de
ùëò(n√∫mero de clusters). A SSE √© definida como a soma das dist√¢ncias ao quadrado entre cada ponto de dados e o centroide do seu cluster mais pr√≥ximo.


"""

wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, random_state = 42)
    kmeans.fit(normalized_base.iloc[:, :-1])
    wcss.append(kmeans.inertia_)

# Plotando o gr√°fico
elbow_normalized_base = normalized_base.copy()
elbow_nor
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), wcss, marker='o')
plt.xlabel('N√∫mero de Clusters')
plt.ylabel('Soma dos quadrados dos erros')
plt.title('Elbow')
plt.show()

"""Aplicando K-means com k = 3 ( n√∫mero onde temos a "dobra do cotovelo" no gr√°fico )"""

kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(normalized_base.iloc[:, :-1])

"""# Silhouette

O m√©todo Silhouette √© uma maneira de avaliar a qualidade do agrupamento medindo o qu√£o semelhante cada ponto de dados √© ao seu pr√≥prio cluster (coes√£o) em compara√ß√£o com outros clusters (separa√ß√£o). A pontua√ß√£o silhouette para um ponto de dados √© calculada como:

S(i) = (b(i) - a(i)) / max(a(i), b(i))

Onde:

* S(i) √© a pontua√ß√£o silhouette do ponto de dados i;
* a √© a dist√¢ncia m√©dia intra-cluster, ou seja a dist√¢ncia m√©dia de cada ponto dentro do cluster;
* b √© a dist√¢ncia m√©dia inter-cluster, ou seja a dist√¢ncia m√©dia de todos os clusteres
"""

silhouette_media = silhouette_score(normalized_base.iloc[:, :-1], clusters)
print(silhouette_media)

aux_normalized_base = normalized_base.copy()
aux_normalized_base['cluster'] = clusters
aux_normalized_base['true_class'] = base['class']

"""M√©dia de cada cluster"""

cluster_means = aux_normalized_base.drop(columns=['class', 'true_class']).groupby('cluster').mean()
print(cluster_means)

plt.figure(figsize=(10, 6))
plt.scatter(aux_normalized_base['sepallength'], aux_normalized_base['sepalwidth'], c=aux_normalized_base['cluster'], cmap='viridis', marker='o', label='Cluster correto')
plt.scatter(incorrectly_clustered['sepallength'], incorrectly_clustered['sepalwidth'], c='red', marker='x', label='Cluster incorreto')

"""#Calinski Harabasz

A m√©trica Calinski-Harabasz √© utilizada para avaliar a qualidade dos clusters gerados pelo K-Means. Essa m√©trica mede a rela√ß√£o entre a dispers√£o dentro dos clusters e a dispers√£o entre os clusters. Quanto maior o valor do √≠ndice Calinski-Harabasz, melhor √© a separa√ß√£o entre os clusters.

A f√≥rmula do √≠ndice Calinski-Harabasz (CHi) √© dada por:

CHi = ( B(K)/W(K) ) x ( N-K / K-1 )
"""

normalized_base

from sklearn.metrics import calinski_harabasz_score

calinski_harabasz_scores = []

for i in range(2, 11):
    kmeans = KMeans(n_clusters=i, random_state=42)
    clusters = kmeans.fit_predict(normalized_base.iloc[:, :-1])
    score = calinski_harabasz_score(normalized_base.iloc[:, :-1], clusters)
    calinski_harabasz_scores.append(score)

ch_normalized_base = normalized_base.copy()
ch_normalized_base['cluster'] = clusters
ch_normalized_base['true_class'] = base['class']

incorrectly_clustered = ch_normalized_base[ch_normalized_base['cluster'] != ch_normalized_base['true_class'].map({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})]
plt.figure(figsize=(10, 6))
plt.scatter(ch_normalized_base['sepallength'], ch_normalized_base['sepalwidth'], c=ch_normalized_base['cluster'], cmap='viridis', marker='o', label='Cluster correto')
plt.scatter(incorrectly_clustered['sepallength'], incorrectly_clustered['sepalwidth'], c='red', marker='x', label='Cluster incorreto')
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.title('Visualiza√ß√£o de Agrupamentos Incorretos')
plt.legend()
plt.show()

plt.plot(range(2, 11), calinski_harabasz_scores, marker='o')
plt.xlabel('N√∫mero de Clusters')
plt.ylabel('√çndice Calinski-Harabasz')
plt.title('M√©todo Calinski-Harabasz')
plt.show()

"""# Relat√≥rio

Etapas de Pr√©-processamento:
- Carregamento dos Dados:

Utilizamos dados de amostra da base Iris com os primeiros 20 exemplos.
- Normaliza√ß√£o dos Dados:

Normalizamos os dados utilizando Min-Max Scaling para trazer os valores para o intervalo [0, 1].

- Clusteriza√ß√£o com K-means:

Aplicamos o algoritmo K-means para agrupar os dados em 3 clusters.
* Avalia√ß√£o dos Agrupamentos:
 - Pontua√ß√£o Silhouette:

Calculamos a pontua√ß√£o Silhouette para avaliar a coes√£o e separa√ß√£o dos clusters.




√çndice Calinski-Harabasz:

Calculamos o √≠ndice Calinski-Harabasz para avaliar a qualidade da separa√ß√£o dos clusters.


* Resultados:

Identificamos inst√¢ncias que foram agrupadas incorretamente pelo K-means em rela√ß√£o √†s classes reais.
A visualiza√ß√£o mostrou que a maioria das inst√¢ncias foram agrupadas incorretamente.
"""

